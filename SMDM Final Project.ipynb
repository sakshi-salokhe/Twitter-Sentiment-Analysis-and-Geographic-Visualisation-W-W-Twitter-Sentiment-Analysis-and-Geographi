{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES\n",
    "\n",
    "from twitter import *\n",
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener \n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import io\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as DT\n",
    "import hmac\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import vincenty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTING CONSUMER KEYS AND TOKEN TO EXTRACT DATA AND FOR AUTHENTICATION\n",
    "\n",
    "consumer_key = \"WTVmpVjjdfasLC9qsKtwiVjo2\"\n",
    "consumer_secret = \"PxDZtP09YSV4liM8mnlSOsHT2JjY84bpCrePOoPllT8n3QF2Z2\"\n",
    "access_token = \"966021915486883841-KsyHF4NZLezaJSD5j0zHdMTFcC9XKFr\"\n",
    "access_secret = \"zE4CJh6fi2BytlFsWb9GAtFnd6t9xPtwLWJsAb5QsPjve\"\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACTING THE TOP TRENDING HASHTAGS IN DESCENDING ORDER\n",
    "\n",
    "trends1 = api.trends_place(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO CALCULATE PERCENTAGE (FOR SENTIMENT ANALYSIS RESULTS)\n",
    "\n",
    "def percentage(part,whole):\n",
    "    return 100*float(part)/float(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO EXTRACT THE TWEETS\n",
    "\n",
    "def extract_tweets(x,i,number):\n",
    "    @classmethod\n",
    "    def parse(cls, api, raw):\n",
    "        status = cls.first_parse(api, raw)\n",
    "        setattr(status, 'json', json.dumps(raw))\n",
    "        return status\n",
    "    # Status() is the data model for a tweet\n",
    "    tweepy.models.Status.first_parse = tweepy.models.Status.parse\n",
    "    tweepy.models.Status.parse = parse\n",
    "        \n",
    "    positive=0\n",
    "    negative=0\n",
    "    neutral=0\n",
    "    polarity=0\n",
    "    \n",
    "    geolocator = Nominatim()\n",
    "    \n",
    "    #STORES DATA INTO CSV FILE\n",
    "    #COLUMNS INCLUDED IN THE CSV FILE = \"USER LOCATION, TOP TWEETS EXTRACTED, SENTIMENT LABEL(BASED ON SENTIMENT ANALYSIS PERFORMED, LATITUDE AND THE LONGITUDE)\n",
    "    \n",
    "    csvFile = open('FINAL_TEST.csv','w', encoding = 'utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    csvWriter.writerow(['User_location', 'tweet_text', 'sentiment_label','coordinates_lat','coordinates_long'])\n",
    "    count = 0\n",
    "    \n",
    "    #SENTIMENT ANALYSIS BEING PERFORMED\n",
    "    \n",
    "    for tweet in tweepy.Cursor(api.search,q=\"%s\" % i,lang='en').items():\n",
    "        if (tweet.user.location != \"\"):\n",
    "            if(count==number):\n",
    "                break\n",
    "            else:\n",
    "                tw = tweet.text\n",
    "                analysis = TextBlob(tw)\n",
    "                polarity += analysis.sentiment.polarity\n",
    "    \n",
    "                if(analysis.sentiment.polarity == 0):\n",
    "                    neutral += 1\n",
    "                    sentiment_label = 'blue'\n",
    "                    \n",
    "                elif(analysis.sentiment.polarity < 0.00):\n",
    "                    negative += 1\n",
    "                    sentiment_label = 'red'\n",
    "                    \n",
    "                elif(analysis.sentiment.polarity > 0.00):\n",
    "                    positive += 1\n",
    "                    sentiment_label = 'green'\n",
    "                \n",
    "                #USER LOCATION IS CONVERTED INTO LATITUDE AND LONGITUDE COORDINATES\n",
    "                location1 = geolocator.geocode(tweet.user.location)\n",
    "               # print(location1)\n",
    "                if location1 is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    lat = location1.latitude\n",
    "                    long = location1.longitude\n",
    "                \n",
    "                #WRITING THE EXTRACTED DATA TO CSV FILE\n",
    "                csvWriter.writerow([tweet.user.location, tweet.text, sentiment_label,lat,long])\n",
    "                count = count + 1\n",
    "    \n",
    "    #SORTING DATA INTO CATEGORIES( POSITIVE, NEUTRAL, NEGATIVE) AFTER SENTIMENT ANALYSIS\n",
    "    neutral = percentage(neutral, number)\n",
    "    positive = percentage(positive, number)\n",
    "    negative = percentage(negative, number)\n",
    "    polarity = polarity/number\n",
    "\n",
    "    positive=format(positive, '.2f')\n",
    "    negative=format(negative, '.2f')\n",
    "    neutral=format(neutral, '.2f')\n",
    "    \n",
    "    #print(\"How people are reacting on \"+searchTerm+\" by analyzing \"+str(number)+\" Tweets.\")\n",
    "\n",
    "    if(polarity == 0):\n",
    "        print(\"Neutral\")\n",
    "    elif(polarity < 0):\n",
    "        print(\"Negative\")\n",
    "    elif(polarity > 0):\n",
    "        print(\"Positive\")\n",
    "\n",
    "    #PUTTING LABELS TO THE CATEGORIZED DATA => POSITIVE: YELLOWGREEN, NEGATIVE: RED, NEUTRAL:BLUE\n",
    "    labels=['Positive['+str(positive)+'%]','Negative['+str(negative)+'%]','Neutral['+str(neutral)+'%]']\n",
    "    sizes=[positive,negative,neutral]\n",
    "    colors=['yellowgreen','red','blue']\n",
    "    patches,texts=plt.pie(sizes,colors=colors,startangle=90)\n",
    "    plt.legend(patches,labels,loc=\"best\")\n",
    "    #plt.title(\"How people are reacting on \"+searchTerm+\" by analyzing \"+str(noOfSearchTerms)+\" Tweets.\")\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    csvFile.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALLING THE FUNCTIONS AND THEIR EXECUTION TO EXTRACT TWEETS, SAVE DATA AND PERFORM THE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#EXTRACTING TOP 10 TRENDING HASHTAGS AND DISPLAYING THEM TO THE USER\n",
    "data = trends1[0] \n",
    "trends = data['trends']\n",
    "\n",
    "names = [trend['name'] for trend in trends]\n",
    "names1=names[0:10]\n",
    "\n",
    "for i in names1:\n",
    "    print(names1.index(i)+1,i)\n",
    "print(\"\\n\")\n",
    "\n",
    "#TAKING THE SERIAL NUMBER OF THE TOP 10 DISPLAYED HASHTAGS FROM USER FOR PERFORMING ANALYSIS\n",
    "a = input(\"serial number of the hashtag to be analysed:\\n\")\n",
    "x = int(a)\n",
    "x= x - 1\n",
    "print(\"you have selected \" ,names1[x])\n",
    "\n",
    "#TAKING INPUT FROM USER FOR THE NUMBER OF TWEETS THAT HE WANTS TO ANALYSE FOR THE CHOSEN HASHTAG\n",
    "number = int(input(\"Enter the number of tweets to analyze\"))\n",
    "\n",
    "tw_count = extract_tweets(x,names[x],number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING THE LOCATION ON MAP ACCORDING TO THE LABELS(COLOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.tile_providers import CARTODBPOSITRON\n",
    "from bokeh.models import ColumnDataSource, GMapOptions\n",
    "from bokeh.plotting import gmap\n",
    "\n",
    "from bokeh.io import output_file, output_notebook, show\n",
    "from bokeh.models import (\n",
    "  GMapPlot, GMapOptions, ColumnDataSource, Circle, LogColorMapper, BasicTicker, ColorBar,\n",
    "    DataRange1d, PanTool, WheelZoomTool, BoxSelectTool\n",
    ")\n",
    "#NAMES OF THE COLUMNS TO BE USED FOR PLOTTING ON GRAPH\n",
    "col_names = ['sentiment_label', 'coordinates_lat', 'coordinates_long']\n",
    "\n",
    "#READING THE CSV FILE FOR EXTRACTING THE STORED DATA\n",
    "df = pd.read_csv('FINAL_TEST.csv', header=None, names = col_names)\n",
    "\n",
    "#CONVERTING THE DATA FROM NEEDED COLUMNS INTO RESPECTIVE LISTS WITHOUT HEADERS\n",
    "lat1 = df.coordinates_lat.tolist()[1:]\n",
    "long1 = df.coordinates_long.tolist()[1:]\n",
    "color = df.sentiment_label.tolist()[1:]\n",
    "\n",
    "# print(\"Lat:\",lat1)\n",
    "# print(\"\\n\")\n",
    "# print(\"long:\",long1)\n",
    "# print(\"\\n\")\n",
    "# print(\"Color:\",color)\n",
    "# print(\"\\n\")\n",
    "\n",
    "#EXTRACTION OF FIRST VALUES OF THE LISTS FOR SETTING THE START COORDINATES ON MAP\n",
    "LAT = map(float,lat1) \n",
    "LONG = map(float,long1) \n",
    "COLOR = map(str,color)\n",
    "\n",
    "for x in LAT:\n",
    "    x=x\n",
    "    break\n",
    "for y in LONG:\n",
    "    y=y\n",
    "    break\n",
    "    \n",
    "    \n",
    "source = ColumnDataSource(\n",
    "    data=dict(lat=lat1,\n",
    "              long=long1,\n",
    "              color=color)\n",
    ")\n",
    "\n",
    "#SETTING THE START COORDINATES AND DETAILS OF THE MAP TO BE DISPLAYED\n",
    "map_options = GMapOptions(lat=x, lng=y, map_type=\"roadmap\", zoom=1)\n",
    "\n",
    "#SETTING API KEYS AND TITLE FOR THE MAP TO BE DISPLAYED\n",
    "p = gmap(\"AIzaSyDBVcQw2-aEXePo0nS3H2zUPP4c5BCIKJc\",map_options, title=\"FINAL PLOT\")\n",
    "\n",
    "#DATA TO BE PLOTTED\n",
    "p.circle(x=\"long\", y=\"lat\", size=5, fill_color='color', fill_alpha=0.8, source = source )\n",
    "\n",
    "#FINAL OUTPUT\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
